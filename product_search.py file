import aiohttp
import asyncio
from bs4 import BeautifulSoup
import re
from urllib.parse import quote_plus, urljoin
import logging
from typing import Dict, Optional, Any
from dataclasses import dataclass
from decimal import Decimal
import json

@dataclass
class ProductPrice:
    price: Optional[Decimal]
    url: str
    in_stock: bool
    model_number: Optional[str]
    sku: Optional[str]
    raw_price: str

@dataclass
class SearchResult:
    product_name: Optional[str]
    brand: Optional[str]
    model_number: Optional[str]
    category: Optional[str]
    retailers: Dict[str, ProductPrice]
    description: Optional[str]
    specifications: Dict[str, str]
    error: Optional[str]

class RetailerError(Exception):
    """Base exception for retailer-specific errors"""
    pass

class ProductSearcher:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Connection': 'keep-alive',
        }
        self.logger = logging.getLogger(__name__)
        self.setup_logging()

    def setup_logging(self):
        """Configure logging"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

    def clean_price(self, price_str: str) -> Optional[Decimal]:
        """Clean and convert price string to Decimal"""
        try:
            if not price_str or price_str == 'N/A':
                return None
            # Remove currency symbols and convert to number
            cleaned = re.sub(r'[^\d.]', '', price_str)
            return Decimal(cleaned) if cleaned else None
        except Exception as e:
            self.logger.error(f"Error cleaning price {price_str}: {str(e)}")
            return None

    async def search_all_retailers(self, product_number: str, brand: Optional[str] = None) -> SearchResult:
        """Search all retailers for a product with enhanced error handling"""
        self.logger.info(f"Searching for product: {product_number} (Brand: {brand})")
        
        # Validate input
        if not self._validate_product_number(product_number):
            return SearchResult(
                product_name=None,
                brand=brand,
                model_number=product_number,
                category=None,
                retailers={},
                description=None,
                specifications={},
                error="Invalid product number format"
            )

        # Search tasks
        tasks = [
            self._safe_search(self.search_ferguson, product_number, brand, "Ferguson"),
            self._safe_search(self.search_homedepot, product_number, brand, "Home Depot"),
            self._safe_search(self.search_lowes, product_number, brand, "Lowes"),
            self._safe_search(self.search_supply, product_number, brand, "Supply.com"),
            self._safe_search(self.search_build, product_number, brand, "Build.com")
        ]

        results = await asyncio.gather(*tasks)
        
        # Combine results
        combined = self._combine_search_results(results, product_number, brand)
        self.logger.info(f"Search completed for {product_number}. Found {len(combined.retailers)} results")
        return combined

    async def _safe_search(self, search_func, product_number: str, brand: Optional[str], retailer_name: str) -> SearchResult:
        """Wrapper for safe execution of search functions"""
        try:
            return await search_func(product_number, brand)
        except Exception as e:
            self.logger.error(f"Error searching {retailer_name}: {str(e)}")
            return SearchResult(
                product_name=None,
                brand=None,
                model_number=product_number,
                category=None,
                retailers={},
                description=None,
                specifications={},
                error=f"Error searching {retailer_name}: {str(e)}"
            )

    async def search_ferguson(self, product_number: str, brand: Optional[str] = None) -> SearchResult:
        """Enhanced Ferguson search with better parsing and validation"""
        base_url = "https://www.ferguson.com"
        direct_url = f"{base_url}/product/{product_number}"
        search_url = f"{base_url}/search/{quote_plus(f'{brand or ''} {product_number}')}"
        
        async with aiohttp.ClientSession(headers=self.headers) as session:
            # Try direct product URL first
            try:
                async with session.get(direct_url) as response:
                    if response.status == 200:
                        html = await response.text()
                        return self._parse_ferguson_page(html, direct_url)
            except Exception as e:
                self.logger.warning(f"Direct Ferguson URL failed: {str(e)}")

            # Try search page if direct fails
            try:
                async with session.get(search_url) as response:
                    if response.status == 200:
                        html = await response.text()
                        return self._parse_ferguson_search(html, search_url)
            except Exception as e:
                raise RetailerError(f"Ferguson search failed: {str(e)}")

    def _parse_ferguson_page(self, html: str, url: str) -> SearchResult:
        """Enhanced Ferguson page parser with more data extraction"""
        soup = BeautifulSoup(html, 'html.parser')
        
        # Extract structured data if available
        structured_data = self._extract_structured_data(soup)
        
        # Extract basic product info
        product_name = self._safe_extract(soup, 'h1', {'class': 'product-title'})
        brand = self._safe_extract(soup, 'span', {'class': 'product-brand'})
        model_number = self._safe_extract(soup, 'span', {'class': 'model-number'})
        price_elem = soup.find('span', {'class': 'product-price'})
        price_str = price_elem.text.strip() if price_elem else 'N/A'
        
        # Extract specifications
        specs = {}
        specs_container = soup.find('div', {'class': 'specifications'})
        if specs_container:
            for row in specs_container.find_all('tr'):
                cols = row.find_all('td')
                if len(cols) == 2:
                    specs[cols[0].text.strip()] = cols[1].text.strip()

        # Check stock status
        in_stock = self._check_stock_status(soup)
        
        # Create price object
        price = ProductPrice(
            price=self.clean_price(price_str),
            url=url,
            in_stock=in_stock,
            model_number=model_number,
            sku=self._safe_extract(soup, 'span', {'class': 'sku'}),
            raw_price=price_str
        )

        return SearchResult(
            product_name=product_name,
            brand=brand,
            model_number=model_number,
            category=self._extract_category(soup),
            retailers={'ferguson': price},
            description=self._safe_extract(soup, 'div', {'class': 'product-description'}),
            specifications=specs,
            error=None
        )

    def _validate_product_number(self, product_number: str) -> bool:
        """Validate product number format"""
        if not product_number:
            return False
        
        # Common patterns for different brands
        patterns = {
            'kohler': r'^[Kk]-\d{4}(-\d+)?$',
            'toto': r'^[Cc][Ss][Tt]\d{3,4}[A-Za-z]?$',
            'american_standard': r'^[0-9A-Z]{4,8}$',
            'delta': r'^[0-9A-Z]{3,10}$',
            'moen': r'^[0-9A-Z]{4,12}$'
        }
        
        return any(re.match(pattern, product_number) for pattern in patterns.values())

    def _safe_extract(self, soup: BeautifulSoup, tag: str, attrs: Dict) -> Optional[str]:
        """Safely extract text from BeautifulSoup element"""
        try:
            element = soup.find(tag, attrs)
            return element.text.strip() if element else None
        except Exception as e:
            self.logger.warning(f"Error extracting {tag} with attrs {attrs}: {str(e)}")
            return None

    def _extract_structured_data(self, soup: BeautifulSoup) -> Optional[Dict]:
        """Extract structured data from page"""
        try:
            for script in soup.find_all('script', type='application/ld+json'):
                try:
                    return json.loads(script.string)
                except:
                    continue
        except Exception as e:
            self.logger.warning(f"Error extracting structured data: {str(e)}")
            return None

    def _check_stock_status(self, soup: BeautifulSoup) -> bool:
        """Check if product is in stock"""
        try:
            stock_elem = soup.find('div', {'class': 'stock-status'})
            if stock_elem:
                return 'in stock' in stock_elem.text.lower()
            return False
        except Exception as e:
            self.logger.warning(f"Error checking stock status: {str(e)}")
            return False

    def _combine_search_results(self, results: list, product_number: str, brand: Optional[str]) -> SearchResult:
        """Combine results from multiple retailers"""
        combined = SearchResult(
            product_name=None,
            brand=brand,
            model_number=product_number,
            category=None,
            retailers={},
            description=None,
            specifications={},
            error=None
        )

        errors = []
        for result in results:
            if result.error:
                errors.append(result.error)
            
            # Update product info if not already set
            if not combined.product_name and result.product_name:
                combined.product_name = result.product_name
            if not combined.brand and result.brand:
                combined.brand = result.brand
            if not combined.category and result.category:
                combined.category = result.category
            
            # Merge retailers
            combined.retailers.update(result.retailers)
            
            # Merge specifications
            combined.specifications.update(result.specifications)

        if errors and not combined.retailers:
            combined.error = "; ".join(errors)

        return combined

    # Add similar enhanced implementations for other retailers...
